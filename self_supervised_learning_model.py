# -*- coding: utf-8 -*-
"""Self_Supervised_Learning_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CwEs6nWpaDSXADMUjyHUa7Vct5wdyTXx
"""

import torch
import torch.nn as nn
import torchvision.models as models
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import os
from pathlib import Path
import cv2
from collections import defaultdict
import random
import numpy as np

class ShotEncoder(nn.Module):
    def __init__(self, output_dim=128, use_projection=True):
        super().__init__()
        # Load ResNet50 backbone
        resnet = models.resnet50(pretrained=True)
        self.encoder = nn.Sequential(*list(resnet.children())[:-1])

        if use_projection:
            # Add projection head (as per MoCo v2)
            self.projector = nn.Sequential(
                nn.Linear(2048, 2048),
                nn.ReLU(),
                nn.Linear(2048, output_dim)
            )
        else:
            self.projector = nn.Identity()

    def forward(self, x):
        h = self.encoder(x)
        h = h.view(h.size(0), -1)
        z = self.projector(h)
        return F.normalize(z, dim=1)

class ShotDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = Path(root_dir)
        self.transform = transform or transforms.Compose([
            transforms.ToPILImage(),
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                               std=[0.229, 0.224, 0.225])
        ])

        # Create movie-wise shot mappings
        self.shots = defaultdict(list)
        for movie_dir in self.root_dir.glob("Movie_*"):
            movie_id = movie_dir.name
            shots = sorted(list(movie_dir.glob("shot_segment_*.mp4")),
                         key=lambda x: int(x.stem.split('_')[2]))
            self.shots[movie_id] = shots

        # Create flat list of all shots for indexing
        self.all_shots = [(movie_id, shot_path)
                         for movie_id, shots in self.shots.items()
                         for shot_path in shots]

    def _load_video_frame(self, video_path):
        cap = cv2.VideoCapture(str(video_path))
        success, frame = cap.read()
        cap.release()
        if not success:
            raise ValueError(f"Could not read frame from {video_path}")
        return cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    def _get_temporal_neighbors(self, movie_id, shot_idx, window_size=5):
        """Get temporally adjacent shots within window_size"""
        movie_shots = self.shots[movie_id]
        current_idx = next(i for i, shot in enumerate(movie_shots)
                         if shot.stem == shot_idx.stem)

        start_idx = max(0, current_idx - window_size)
        end_idx = min(len(movie_shots), current_idx + window_size + 1)

        return movie_shots[start_idx:end_idx]

    def __getitem__(self, idx):
        movie_id, anchor_path = self.all_shots[idx]

        # Get temporal neighbors
        temporal_neighbors = self._get_temporal_neighbors(movie_id, anchor_path)

        # Sample positive (temporally close)
        positive_path = random.choice(temporal_neighbors)

        # Load and transform frames
        anchor_frame = self._load_video_frame(anchor_path)
        positive_frame = self._load_video_frame(positive_path)

        if self.transform:
            anchor_frame = self.transform(anchor_frame)
            positive_frame = self.transform(positive_frame)

        return anchor_frame, positive_frame

    def __len__(self):
        return len(self.all_shots)

class SceneBoundaryMoCo(nn.Module):
    def __init__(self,
                 K=65536,  # queue size
                 m=0.999,  # momentum
                 T=0.07,   # temperature
                 output_dim=128,
                 batch_size=32):
        super(SceneBoundaryMoCo, self).__init__()  # Properly initialize nn.Module

        self.K = K
        self.m = m
        self.T = T
        self.batch_size = batch_size

        # Create encoders
        self.encoder_q = ShotEncoder(output_dim=output_dim)
        self.encoder_k = ShotEncoder(output_dim=output_dim)

        for param_q, param_k in zip(self.encoder_q.parameters(),
                                  self.encoder_k.parameters()):
            param_k.data.copy_(param_q.data)
            param_k.requires_grad = False

        # Create the queue - now properly registered as buffers
        self.register_buffer("queue", torch.randn(output_dim, K))
        self.queue = F.normalize(self.queue, dim=0)
        self.register_buffer("queue_ptr", torch.zeros(1, dtype=torch.long))

        # Move model to GPU if available
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.to(self.device)

    @torch.no_grad()
    def _momentum_update_key_encoder(self):
        """MoCo momentum update for key encoder"""
        for param_q, param_k in zip(self.encoder_q.parameters(),
                                  self.encoder_k.parameters()):
            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)

    @torch.no_grad()
    def _dequeue_and_enqueue(self, keys):
        batch_size = keys.shape[0]
        ptr = int(self.queue_ptr)

        # Replace the keys at ptr (dequeue and enqueue)
        if ptr + batch_size > self.K:
            # Handle queue wrapping
            remaining = self.K - ptr
            self.queue[:, ptr:] = keys[:remaining].T
            self.queue[:, :batch_size-remaining] = keys[remaining:].T
            ptr = batch_size - remaining
        else:
            self.queue[:, ptr:ptr + batch_size] = keys.T
            ptr = (ptr + batch_size) % self.K

        self.queue_ptr[0] = ptr

    def forward(self, im_q, im_k):
        """Forward pass - required for nn.Module"""
        # Compute query features
        q = self.encoder_q(im_q)  # queries: NxC

        # Compute key features
        with torch.no_grad():  # no gradient to keys
            k = self.encoder_k(im_k)  # keys: NxC

        # Compute logits
        l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)
        l_neg = torch.einsum('nc,ck->nk', [q, self.queue.clone().detach()])

        # Logits: Nx(1+K)
        logits = torch.cat([l_pos, l_neg], dim=1)

        # Apply temperature
        logits /= self.T

        # Dequeue and enqueue
        self._dequeue_and_enqueue(k)

        return logits

    def training_step(self, batch):
        """Single training step with MoCo"""
        im_q, im_k = [b.to(self.device) for b in batch]

        # Forward pass
        logits = self(im_q, im_k)

        # Labels: positives are the 0-th
        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(self.device)

        loss = F.cross_entropy(logits, labels)
        return loss

    def train_epoch(self, train_loader, optimizer):
        """Train for one epoch"""
        total_loss = 0
        n_batches = 0

        for batch in train_loader:
            optimizer.zero_grad()
            loss = self.training_step(batch)
            loss.backward()
            optimizer.step()

            # MoCo momentum update
            self._momentum_update_key_encoder()

            total_loss += loss.item()
            n_batches += 1

        return total_loss / n_batches

    def train(self, train_dir, num_epochs=100, lr=3e-4):
        """Training loop"""
        dataset = ShotDataset(train_dir)
        dataloader = DataLoader(
            dataset,
            batch_size=self.batch_size,
            shuffle=True,
            num_workers=4,
            pin_memory=True
        )

        optimizer = torch.optim.Adam(self.encoder_q.parameters(), lr=lr)

        for epoch in range(num_epochs):
            avg_loss = self.train_epoch(dataloader, optimizer)
            print(f"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}")

    def save_model(self, path):
        """Save query encoder"""
        torch.save(self.encoder_q.state_dict(), path)

    def load_model(self, path):
        """Load query encoder"""
        self.encoder_q.load_state_dict(torch.load(path))



import os
import torch
import random
import numpy as np
from datetime import datetime
from pathlib import Path
import json

def save_config(config, save_dir):
    """Save training configuration"""
    config_path = save_dir / 'config.json'
    with open(config_path, 'w') as f:
        json.dump(config, f, indent=4)

def main():
    config = {
        'data_dir': './AllMovies',
        'save_dir': './experiments',

        'epochs': 5,
        'batch_size': 32,
        'learning_rate': 3e-4,

        'queue_size': 65536,
        'moco_dim': 128,
        'moco_momentum': 0.999,
        'temperature': 0.07,

        'checkpoint_path': None
    }

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    save_dir = Path(config['save_dir']) / timestamp
    save_dir.mkdir(parents=True, exist_ok=True)

    print(f"Configuration: {config}")

    save_config(config, save_dir)

    model = SceneBoundaryMoCo(
        K=config['queue_size'],
        m=config['moco_momentum'],
        T=config['temperature'],
        output_dim=config['moco_dim'],
        batch_size=config['batch_size']
    )

    start_epoch = 0
    if config['checkpoint_path']:
        checkpoint = torch.load(config['checkpoint_path'])
        model.encoder_q.load_state_dict(checkpoint['encoder_q'])
        model.encoder_k.load_state_dict(checkpoint['encoder_k'])
        model.queue = checkpoint['queue']
        model.queue_ptr = checkpoint['queue_ptr']
        start_epoch = checkpoint['epoch'] + 1
        print(f"Resumed from checkpoint: {config['checkpoint_path']}")

    for epoch in range(start_epoch, config['epochs']):
        print(f"Starting epoch {epoch + 1}/{config['epochs']}")

        model.train(
            train_dir=config['data_dir'],
            num_epochs=1,
            lr=config['learning_rate']
        )

        checkpoint = {
            'epoch': epoch,
            'encoder_q': model.encoder_q.state_dict(),
            'encoder_k': model.encoder_k.state_dict(),
            'queue': model.queue,
            'queue_ptr': model.queue_ptr
        }

        latest_path = save_dir / 'checkpoint_latest.pth'
        torch.save(checkpoint, latest_path)

        if (epoch + 1) % 10 == 0:
            checkpoint_path = save_dir / f'checkpoint_epoch_{epoch+1}.pth'
            torch.save(checkpoint, checkpoint_path)
            print(f"Saved checkpoint: {checkpoint_path}")

    final_path = save_dir / 'model_final.pth'
    torch.save({
        'encoder_q': model.encoder_q.state_dict(),
        'encoder_k': model.encoder_k.state_dict(),
        'queue': model.queue,
        'queue_ptr': model.queue_ptr
    }, final_path)
    print(f"Saved final model: {final_path}")

if __name__ == '__main__':
    main()
